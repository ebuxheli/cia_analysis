---
title: "Replication of Partners in Crime: An Empirical Evaluation of the CIA Rendition, Detention, and Interrogation Program"
author: "Enxhi Buxheli"
output: pdf_document
---

## TODO: Add bibliography

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

# attaching necessary libraries
library("foreign")
library("gdata")
library("plyr")
library("dplyr")
library("tidyr")
library("ggplot2")
library("stargazer")
library("plm")
library("Amelia")
library("MKmisc")
library("lmtest")
library("janitor")
```

```{r, cache=TRUE}
## Data: Originally there were three datasets used in analysis: 
# 1. "pic_data_not_imputed.RData" - this is the initial dataset before
#     imputation 
# 2. "pic_data_imputed.RData" - this is the initial imputed dataset, contraining
#     observations from 1991-2011 
# 3. "pic_data.RData" - this is the final dataset used in analysis

# Loading in the data created by author of the paper (unable to run the data
# myself because of the 40 hour run time necessary)

# Average of the imputed datasets for plotting (pic_data.RData). 
## This is the only dataset that was used for the creation of the plots in the
## paper. The other .RData files present in the dataverse_files folder are
## unnecessary and remnants of the data pre-processing. For that reason, I will
## only be including this file in my code.
### This replaces the existing data (non-imputed dataset output) variable. Unsure
### of the intent of this by the author, but I don't believe that this is the
### intended outcome.
load("dataverse_files/pic_data.RData") 

# Retrieving number of imputations in the dataset
imps <- length(data$imputations)

# Creating a key of the country codes to be later rematched with the average of
# the imputed data. When the average of the imputed data is taken, the contents
# of the country variable are deleted and this is a way to restore that
# information.

# Creating the country key
data_country <- data$imputations[[1]] %>% 
  distinct(COW, country)

# Average of imputed dataset  
data_analyze <- (data$imputations[[1]] + data$imputations[[2]] + 
                   data$imputations[[3]] + data$imputations[[4]] + 
                   data$imputations[[5]] + data$imputations[[6]] + 
                   data$imputations[[7]] + data$imputations[[8]] + 
                   data$imputations[[9]])/imps

# Joining the datasets and cleaning up variable names for sanity sake (the
# varying capitalizations of variable names was maddening)
data_final <- inner_join(data_country, data_analyze, 
                         by = "COW", suffix = c(".c", ".a")) %>% 
  select(-country.a, country = country.c) %>% 
  clean_names()
```


# Figure 1
```{r fig1, cache=TRUE}
### TODO: FIGURE OUT A BETTER NAMING CONVENTION FOR THE GRAPHS TO MAKE IT EASIER
### TO CODE AND SEE.

# Plotting figure 1 

# Computing global-year averages for relevant variables
trends_1 <- data_final %>% 
  group_by(year) %>% 
  summarise("Physical Integrity Score (CIRI)"      = mean(physint, na.rm = TRUE),
            "Latent Variable Model Score (Fariss)" = mean(latentmean, na.rm = TRUE),
            "Political Imprisonment Score (CIRI)"  = mean(polpris, na.rm = TRUE),
            "Disappearance Score (CIRI)"           = mean(disap, na.rm = TRUE))

# List of variable names
var_names <- c("Physical Integrity Score (CIRI)", 
               "Latent Variable Model Score (Fariss)", 
               "Disappearance Score (CIRI)", 
               "Political Imprisonment Score (CIRI)")

# Formats the data to be graphed and makes the data facet on var_name
graph_data1 <- gather(trends_1, type, value, var_names)  
graph_data1$type <- factor(graph_data1$type, levels = var_names)

# Creates a tibble with the variable names and the plot limits for each of the
# different plots. Also standardizes the year limits.
var_limits1 <- as_tibble(cbind(year = c(rep(1992:2011, times = 4)), 
                              value = c(rep(c(0, 8),    10), 
                                        rep(c(-0.5, 1), 10), 
                                        rep(c(0, 2),    10), 
                                        rep(c(0, 2),    10))))

# Assign variable names
var_limits1$type <- rep(var_names[1:4], times = 1, each = 20) 

# Converts labels to factors to order plot facets 
var_limits1$type <- factor(var_limits1$type, levels = var_names) 

## TOutputting plot for figure 1
ggplot(graph_data1, aes(x = year, y = value)) +
  geom_line() + 
  geom_vline(xintercept = seq(2001, 2005, by = 0.001), 
             colour = "grey", linetype = "solid", 
             alpha = 0.01) +
  geom_blank(data = var_limits1) +
  facet_wrap(~type, ncol = 2, scales = "free") +
  labs(x = "Year", 
       y = "Lower Score = More Abuse; Higher Score = More Respect") +
  theme_bw() + 
  theme(legend.position = "bottom", legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14), 
        text = element_text(size = 13, family = "Times"),
        axis.title = element_text(size = 10), axis.text = element_text(size = 10))

# Saving the plot output for the presentation
ggsave(paste0("present/fig1.png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")
```

# Figure 2
```{r fig2, cache=TRUE}
# Computing global-year averages for democracies and non-democracies for all var_names
trends_2 <- data_final %>% 
  group_by(year, active_d) %>% 
  summarise("Physical Integrity Score (CIRI)"      = mean(physint, na.rm = TRUE),
            "Latent Variable Model Score (Fariss)" = mean(latentmean, na.rm = TRUE),
            "Political Imprisonment Score (CIRI)"  = mean(polpris, na.rm = TRUE),
            "Disappearance Score (CIRI)"           = mean(disap, na.rm = TRUE))

# Formats the data to be graphed and makes the data facet on var_name
graph_data2 <- gather(trends_2, type, value, var_names)
graph_data2$type <- factor(graph_data2$type, levels = var_names) 

# Relabel active_d for legend using a loop
for (i in 1:length(graph_data2$active_d)){
  if (graph_data2$active_d[i] == 0){
    graph_data2$active_d[i] <- "Other States"
  }
  else if (graph_data2$active_d[i] == 1){
    graph_data2$active_d[i] <- "Active Participants"
  }
}

# Construct matrices to call min and max values for y-axis on facet plots
var_limits2 <- as_tibble(cbind(year = c(rep(1992:2011, times = 4, each = 2)),
                               active_d = c(rep(0:1, times = 40)),
                               value = c(rep(c(0,8),    20), 
                                         rep(c(-0.5,1), 20), 
                                         rep(c(0,2),    20), 
                                         rep(c(0,2),    20))))

# Assign variable names
var_limits2$type <- rep(var_names[1:4], times = 1, each = 40)

# Converts labels to factors to order plot facets
var_limits2$type <- factor(var_limits2$type, levels = var_names)


# Create plots
## Figure 2
ggplot(graph_data2, aes(x = year, y = value, group = active_d)) +
  geom_line(aes(linetype = factor(active_d))) + 
  geom_vline(xintercept = seq(2001, 2005, by = 0.001), 
             colour="grey", linetype = "solid", 
             alpha = 0.01) +
  geom_blank(data = var_limits2) +
  facet_wrap(~type, ncol=2, scales = "free") +
  labs(x = "Year", 
       y = "Lower Score = More Abuse; Higher Score = More Respect") +
  theme_bw() + 
  theme(legend.position = "bottom", legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14), 
        text = element_text(size = 13, family = "Times"),
        axis.title = element_text(size = 10), axis.text = element_text(size = 10))

# Saving the plot output for the presentation
ggsave(paste0("present/fig2.png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")
```

# Figure 3
```{r fig3, cache=TRUE}
# Computing global-year averages for democracies and non-democracies for all var_names
trends_3 <- data_final %>% 
  group_by(year, active_d) %>% 
  filter(below_polity == 1) %>%
  summarise("Physical Integrity Score (CIRI)"      = mean(physint, na.rm = TRUE),
            "Latent Variable Model Score (Fariss)" = mean(latentmean, na.rm = TRUE),
            "Political Imprisonment Score (CIRI)"  = mean(polpris, na.rm = TRUE),
            "Disappearance Score (CIRI)"           = mean(disap, na.rm = TRUE))

# Formats the data to be graphed and makes the data facet on var_name
graph_data3 <- gather(trends_3, type, value, var_names)
graph_data3$type <- factor(graph_data3$type, levels = var_names) 

# Relabel active_d for legend using a loop
for (i in 1:length(graph_data3$active_d)){
  if (graph_data3$active_d[i] == 0){
    graph_data3$active_d[i] <- "Other States"
  }
  else if (graph_data3$active_d[i] == 1){
    graph_data3$active_d[i] <- "Active Participants"
  }
}

# Adjust y-axis for Fariss data
var_limits3 <- as_tibble(cbind(year = c(rep(1992:2011, times = 4, each = 2)),
                                   active_d = c(rep(0:1, times = 40)),
                                   value = c(rep(c(0,8),    20), 
                                             rep(c(-1,0.5), 20), 
                                             rep(c(0,2),    20), 
                                             rep(c(0,2),    20))))

# Assign variable names
var_limits3$type <- rep(var_names[1:4], times = 1, each = 40)

# Converts labels to factors to order plot facets
var_limits3$type <- factor(var_limits3$type, levels = var_names)

# Create Plots
# Figure 3
ggplot(graph_data3, aes(x = year, y = value, group = active_d)) +
  geom_line(aes(linetype = factor(active_d))) + 
  geom_vline(xintercept = seq(2001, 2005, by = 0.001), 
             colour="grey", linetype = "solid", 
             alpha = 0.01) +
  geom_blank(data = var_limits3) +
  facet_wrap(~type, ncol=2, scales = "free") +
  labs(x = "Year", 
       y = "Lower Score = More Abuse; Higher Score = More Respect") +
  theme_bw() + 
  theme(legend.position = "bottom", legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14), 
        text = element_text(size = 13, family = "Times"),
        axis.title = element_text(size = 10), axis.text = element_text(size = 10))

# Saving the plot output for the presentation
ggsave(paste0("present/fig3.png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")
```

# Tables
```{r, include=FALSE, cache=TRUE}
# Conduct a series of difference-of-means tests comparing global human rights
# practices before and after the onset of the RDI program (Part A); and a series
# of difference-of-means tests to check the comparability of participants and
# non-participants before the beginning # of the RDI program (Part B).

# #---------------------------------------------------------------------------------------------
# # Part A. Difference-of-Means Tests of Human Rights Before/After 2001, 2002, 2003, 2004, 2005
# #---------------------------------------------------------------------------------------------
# 
# # Clear workspace and re-load data
# #load("pic_data.RData")
# #data.out <- data
# cutoff_years <- c(2001, 2002, 2003, 2004, 2005) # Creat vectorof relevant cutoff years
# var_names <- c("PHYSINT", "Latent", "State", "Amnesty", "KILL", "POLPRIS", "TORT", "DISAP") # Vector of dependent variable names
# 
# # Function that creates dataset of states' average dependent variable values for before/after cutoff dates  
# average_dv_pre_post <- function(year, df){
#   post_years <- df %>% group_by(COW) %>% filter(year >= year) %>% 
#     summarise(PHYSINT = mean(PHYSINT, na.rm = TRUE), Latent = mean(latentmean, na.rm = TRUE),
#               State = mean(State, na.rm = TRUE), Amnesty = mean(Amnesty, na.rm = TRUE),
#               KILL = mean(KILL, na.rm = TRUE), POLPRIS = mean(POLPRIS, na.rm = TRUE),
#               TORT = mean(TORT, na.rm = TRUE), DISAP = mean(DISAP, na.rm = TRUE))
#   post_years$pre_post <- 1
#   pre_years <- df %>% group_by(COW) %>% filter(year < year) %>% 
#     summarise(PHYSINT = mean(PHYSINT, na.rm = TRUE), Latent = mean(latentmean, na.rm = TRUE),
#               State = mean(State, na.rm = TRUE), Amnesty = mean(Amnesty, na.rm = TRUE),
#               KILL = mean(KILL, na.rm = TRUE), POLPRIS = mean(POLPRIS, na.rm = TRUE),
#               TORT = mean(TORT, na.rm = TRUE), DISAP = mean(DISAP, na.rm = TRUE))
#   pre_years$pre_post <- 0
#   out <- as.data.frame(rbind(pre_years, post_years))
#   out
# }
# 
# data.out.ttest <- data.out # Create object to hold datasets for analysis
# 
# # Run Analysis 
# for(i in 1:length(cutoff_years)){
#   for(j in 1:length(data.out$imputations)){data.out.ttest$imputations[[j]] <- average_dv_pre_post(cutoff_years[i], data.out$imputations[[j]])}
#   cat("\n \n \n \n", "Analysis With Cutoff Year =", cutoff_years[i],"\n \n")
#   for(k in 1:length(var_names)){
#     out <- mi.t.test(data.out.ttest$imputations, x = var_names[k], y = "pre_post", alternative = c("two.sided"), var.equal = FALSE)
#     print(out)
#   }
# }
# # Function that gets country averages for all variables during a specified period
# balance_data <- function(start_year, stop_year, df){
#   out <- df %>% group_by(COW) %>% 
#     filter(year >= start_year & year <= stop_year) %>%
#     summarise(active_d = mean(active_d), PHYSINT = mean(PHYSINT), 
#               Latent = mean(latentmean),State = mean(State), Amnesty = mean(Amnesty),
#               KILL = mean(KILL), POLPRIS = mean(POLPRIS), TORT = mean(TORT), 
#               DISAP = mean(DISAP), ucdp_type3 = mean(ucdp_type3), trans = mean(trans), 
#               log_pop = mean(log_pop), log_gdppc = mean(log_gdppc), polity2 = mean(polity2), 
#               gtd = mean(gtd), log_UStrade = mean(log_UStrade), log_USmilaid = mean(log_USmilaid))
#   out <- as.data.frame(out)
#   out
# }
# data.out.baltest <- data.out # Create object to hold datasets for analysis
# vars <- c("PHYSINT", "Latent", "State", "Amnesty", "KILL", "POLPRIS", "TORT", "DISAP",
#           "ucdp_type3", "trans", "log_pop", "log_gdppc", "polity2", "gtd", "log_UStrade", "log_USmilaid")
# 
# # Run Analysis 
# for(j in 1:length(data.out$imputations)){data.out.baltest$imputations[[j]] <- balance_data(1998, 2000, data.out$imputations[[j]])} # Subset relevant data
# cat("\n \n \n \n", "Balance between Participants and Non-Participants from 1998 until 2000 \n \n") # Print title
# for(k in 1:length(vars)){ # Loop through difference of means tests for all variables and print results
#     out <- mi.t.test(data.out.baltest$imputations, x = vars[k], y = "active_d", alternative = c("two.sided"), var.equal = FALSE)
#     print(out)
# }
```

```{r table23, results='asis'}
############################################
# Section 4. Linear Models
############################################

#-----------------------------------------------------------------------------------------
# In this section we compute a series of linear models for panel data in order
# to assess the correlation between participation in the RDI program and changes
# in state human rights practices. First, we load the data and define functions to compute
# standard errors and four linear panel models from imputed datasets (Part A). All models are
# the same, with the exception of the addition of control variables and the decomposition of
# the participation variable by level of democracy. The first model is commented extensively,
# all others follow the same series of commands. We then use these functions to conduct our
# analysis and present the results (Part B).
#-----------------------------------------------------------------------------------------

#----------------------------------
# Part A. Define relevant functions
#----------------------------------

data.out <- data

# Define Function to Compute Variances from Imputed Datasets
mi.ses <- function(betas, st.errors){
  t_one <- apply(st.errors, MARGIN= 2, function(x) ((1/(length(x))) * sum(x^2)))
  t_two <- apply(betas, MARGIN= 2, 
                 function(x) sum((x - mean(x))^2 /(length(x) - 1)) *(1 + (1/length(x))))
  
  t_one + t_two
}

# General Function for Model 1
mod_1 <- function(variable, lag_var){
  # Step 1. Create empty matrices to store estimated coefficients and standard errors computed for each imputed dataset
  betas <- matrix(NA, nrow = imps, ncol = 2) # Matrix for estimated coefficients
  st.errors <- matrix(NA, nrow = imps, ncol = 2) # Matrix for standard errors

  # Step 2. Create formula
  IVs <- paste("active_t", substitute(lag_var), sep = "+") # Paste together covariates
  fmla <- formula(paste(substitute(variable), IVs, sep = "~")) # Paste on DV and convert to formula

  # Step 3. Estimate linear model and save standard errors for each imputed dataset
  for (i in 1:imps){
    mod <- plm(fmla, data=data.out$imputations[[i]], index=c("COW", "YEAR"), effect ="twoways", model="within") # Compute linear panel model
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group")) # Compute country level cluster robust standard errors
    betas[i,] <- mod[,1] # Save estimated coefficients
    st.errors[i,] <- mod[,2] # Save clustered standard errors
  }

  # Step 4. Compute estimated coefficients and standard errors across all imputed datasets
  beta_estimates <- colMeans(betas) # Compute mean of estimated coefficients across imputed datasets
  crse_estimates <- mi.ses(betas, st.errors) # Compute standard errors across imputed datasets

  # Step 5. Make placeholder plm object and insert correct values for estimated coefficients and standard errors so that results can be presented in a table
  mod <- plm(fmla, data=data.out$imputations[[1]], index=c("COW", "YEAR"), effect ="twoways", model="within") # create placeholder plm object
  for(i in 1:length(colMeans(betas))){mod$coefficients[[i]] <- beta_estimates[i]} # Overwrite plm coefficients with correct coefficients
  diag(mod$vcov) <- crse_estimates # Overwrite diagonal of plm variance-covariance matrix with correct variances

  # Step 6. Return plm object
  mod
}

# General Function for Model 2
mod_2 <- function(DV, LAG_DV){
  betas <- matrix(NA, nrow = imps, ncol = 3)
  st.errors <- matrix(NA, nrow = imps, ncol = 3)
  IVs <- paste("Dem_Part", "Auto_Part", substitute(LAG_DV), sep = "+")
  fmla <- formula(paste(substitute(DV), IVs, sep = "~"))
  for (i in 1:imps){
    mod <- plm(fmla, data=data.out$imputations[[i]], index=c("COW", "YEAR"), effect ="twoways", model="within")
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group"))
    betas[i,] <- mod[,1]
    st.errors[i,] <- mod[,2]
  }
  beta_estimates <- colMeans(betas)
  crse_estimates <- mi.ses(betas, st.errors)
  mod <- plm(fmla, data=data.out$imputations[[1]], index=c("COW", "YEAR"), effect ="twoways", model="within")
  for(i in 1:length(colMeans(betas))){mod$coefficients[[i]] <- beta_estimates[i]}
  diag(mod$vcov) <- crse_estimates
  mod
}

# General Function for Model 3
mod_3 <- function(DV, LAG_DV){
  betas <- matrix(NA, nrow = imps, ncol = 10)
  st.errors <- matrix(NA, nrow = imps, ncol = 10)
  IVs <- paste("active_t", "ucdp_type3", "gtd", "trans", "polity2", "log_pop", "log_gdppc", "log_UStrade", "log_USmilaid", substitute(LAG_DV), sep = "+")
  fmla <- formula(paste(substitute(DV), IVs, sep = "~"))
  for (i in 1:imps){
    mod <- plm(fmla, data=data.out$imputations[[i]], index=c("COW", "YEAR"), effect ="twoways", model="within")
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group"))
    betas[i,] <- mod[,1]
    st.errors[i,] <- mod[,2]
  }
  beta_estimates <- colMeans(betas)
  crse_estimates <- mi.ses(betas, st.errors)
  mod <- plm(fmla, data=data.out$imputations[[1]], index=c("COW", "YEAR"), effect ="twoways", model="within")
  for(i in 1:length(colMeans(betas))){mod$coefficients[[i]] <- beta_estimates[i]}
  diag(mod$vcov) <- crse_estimates
  mod
}

# General Function for Model 4
mod_4 <- function(DV, LAG_DV){
  betas <- matrix(NA, nrow = imps, ncol = 11)
  st.errors <- matrix(NA, nrow = imps, ncol = 11)
  IVs <- paste("Dem_Part", "Auto_Part", "ucdp_type3", "gtd", "trans", "polity2", "log_pop", "log_gdppc", "log_UStrade", "log_USmilaid", substitute(LAG_DV), sep = "+")
  fmla <- formula(paste(substitute(DV), IVs, sep = "~"))
  for (i in 1:imps){
    mod <- plm(fmla, data=data.out$imputations[[i]], index=c("COW", "YEAR"), effect ="twoways", model="within")
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group"))
    betas[i,] <- mod[,1]
    st.errors[i,] <- mod[,2]
  }
  beta_estimates <- colMeans(betas)
  crse_estimates <- mi.ses(betas, st.errors)
  mod <- plm(fmla, data=data.out$imputations[[1]], index=c("COW", "YEAR"), effect ="twoways", model="within")
  for(i in 1:length(colMeans(betas))){mod$coefficients[[i]] <- beta_estimates[i]}
  diag(mod$vcov) <- crse_estimates
  mod
}

#---------------------------------
# Part B. Run and Present Analysis
#---------------------------------

# Define standard fomatting features of tables
covariate_names <- c("Participation", "Democratic participation", "Autocratic participation", "Internal conflicts",
                     "Terrorist attacks", "Transitional state", "Polity score", "Log population",
                     "Log GDP per capita", "Log US trade", "Log US military assistance")
fe_line <- list(c("Fixed effects", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes"))
footnote <- c("Note: All models include country and year fixed effects and a dependent variable lagged one year. Country level",
              "cluster-robust standard errors in parentheses. $^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01")

  #c("All models include country and year fixed effects and a dependent variable lagged one year.",
   #           "Country level cluster-robust standard errors in parentheses. $^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01")
title1 <- "Participation in RDI program and state respect for human rights, 1992-2011"

# Run analysis and produce tables
stargazer(mod_1(PHYSINT, lag_physint), mod_2(PHYSINT, lag_physint), mod_3(PHYSINT, lag_physint), mod_4(PHYSINT, lag_physint),
          mod_1(latentmean, lag_latentmean), mod_2(latentmean, lag_latentmean), mod_3(latentmean, lag_latentmean), mod_4(latentmean, lag_latentmean),
          title = title1, covariate.labels = covariate_names, add.lines = fe_line, notes = footnote,
          dep.var.labels = c("Physical Integrity Score (CIRI)", "Latent Variable Model (Fariss)"),
          digits = 3, omit = c("lag_physint", "lag_latentmean"), omit.stat = c("adj.rsq", "f"),
          notes.append = FALSE, notes.align = "l")

stargazer(mod_1(DISAP, lag_disap), mod_2(DISAP, lag_disap), mod_3(DISAP, lag_disap), mod_4(DISAP, lag_disap),
          mod_1(POLPRIS, lag_polpris), mod_2(POLPRIS, lag_polpris), mod_3(POLPRIS, lag_polpris), mod_4(POLPRIS, lag_polpris),
          title = title1, covariate.labels = covariate_names, add.lines = fe_line, notes = footnote,
          dep.var.labels = c("Disappearance Score (CIRI)", "Political Imprisonment Score (CIRI)"),
          digits = 3, omit = c("lag_disap", "lag_polpris"), omit.stat = c("adj.rsq", "f"),
          notes.append = FALSE, notes.align = "l")
```




