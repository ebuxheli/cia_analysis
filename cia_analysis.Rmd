---
title: "Replication of Partners in Crime: An Empirical Evaluation of the CIA Rendition, Detention, and Interrogation Program"
author: "Enxhi Buxheli"
output: pdf_document
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

# attaching necessary libraries
library("foreign")
library("gdata")
library("plyr")
library("dplyr")
library("tidyr")
library("ggplot2")
library("stargazer")
library("plm")
library("Amelia")
library("MKmisc")
library("lmtest")
library("janitor")
library("readr")
```

```{r data_load, cache=TRUE}
## Data: Originally there were three datasets used in analysis: 
# 1. "pic_data_not_imputed.RData" - this is the initial dataset before
#     imputation 
# 2. "pic_data_imputed.RData" - this is the initial imputed dataset, contraining
#     observations from 1991-2011 
# 3. "pic_data.RData" - this is the final dataset used in analysis

# Loading in the data created by author of the paper (unable to run the data
# myself because of the 40 hour run time necessary)

# Average of the imputed datasets for plotting (pic_data.RData). 
## This is the only dataset that was used for the creation of the plots in the
## paper. The other .RData files present in the dataverse_files folder are
## unnecessary and remnants of the data pre-processing. For that reason, I will
## only be including this file in my code.
### This replaces the existing data (non-imputed dataset output) variable. Unsure
### of the intent of this by the author, but I don't believe that this is the
### intended outcome.
load("dataverse_files/pic_data.RData") 

# Retrieving number of imputations in the dataset
imps <- length(data$imputations)

# Creating a key of the country codes to be later rematched with the average of
# the imputed data. When the average of the imputed data is taken, the contents
# of the country variable are deleted and this is a way to restore that
# information.

# Creating the country key
## COW is the unique country ID given to each country (the number of the
## countries is a bit strange), while country is the actual name of the coutnry.
data_country <- data$imputations[[1]] %>% 
  distinct(COW, country)

# Average of imputed dataset  
data_analyze <- (data$imputations[[1]] + data$imputations[[2]] + 
                   data$imputations[[3]] + data$imputations[[4]] + 
                   data$imputations[[5]] + data$imputations[[6]] + 
                   data$imputations[[7]] + data$imputations[[8]] + 
                   data$imputations[[9]])/imps

# Joining the datasets and cleaning up variable names for sanity sake (the
# varying capitalizations of variable names was maddening). This is the
# datset that I use throughout the paper in order to create the graphs and 
# tables.
data_final <- inner_join(data_country, data_analyze, 
                         by = "COW", suffix = c(".c", ".a")) %>% 
  select(-country.a, country = country.c) %>% 
  clean_names()

## Some data notes:
### cow: unique country id
### country: country name written out
### cyear: country id concatenated with the year [CCCYYYY] (some countries have a 2 digit cow so length varies)
### year: year of data
### t: unknown
### active_d: indicator for whether the country was an active participant in some other sort of interrogation program.
### active_t: indicator for whether the country was an active participant in the RDI program
      ## In the pre-processing code, it is stated that "t" means treatment (this may imply that "d" means data and        
      ## "t" means treatment) [treatment = RDI]
### The rest of the variables are numeric and based upon the CIRI and Farris
###  data. Scoring the countries' human rights ratings on a variety of scales.
```

In (@cia_data).

# Figure 1
```{r fig1, cache=TRUE}
### TODO: FIGURE OUT A BETTER NAMING CONVENTION FOR THE GRAPHS TO MAKE IT EASIER
### TO CODE AND SEE.

# Plotting figure 1 

# Computing global-year averages for relevant variables
trends_1 <- data_final %>% 
  group_by(year) %>% 
  summarise("Physical Integrity Score (CIRI)"      = mean(physint, na.rm = TRUE),
            "Latent Variable Model Score (Fariss)" = mean(latentmean, na.rm = TRUE),
            "Political Imprisonment Score (CIRI)"  = mean(polpris, na.rm = TRUE),
            "Disappearance Score (CIRI)"           = mean(disap, na.rm = TRUE))

# List of variable names
var_names <- c("Physical Integrity Score (CIRI)", 
               "Latent Variable Model Score (Fariss)", 
               "Disappearance Score (CIRI)", 
               "Political Imprisonment Score (CIRI)")

# Formats the data to be graphed and makes the data facet on var_name
graph_data1 <- gather(trends_1, type, value, var_names)  
graph_data1$type <- factor(graph_data1$type, levels = var_names)

# Creates a tibble with the variable names and the plot limits for each of the
# different plots. Also standardizes the year limits.
var_limits1 <- as_tibble(cbind(year = c(rep(1992:2011, times = 4)), 
                              value = c(rep(c(0, 8),    10), 
                                        rep(c(-0.5, 1), 10), 
                                        rep(c(0, 2),    10), 
                                        rep(c(0, 2),    10))))

# Assign variable names
var_limits1$type <- rep(var_names[1:4], times = 1, each = 20) 

# Converts labels to factors to order plot facets 
var_limits1$type <- factor(var_limits1$type, levels = var_names) 

## TOutputting plot for figure 1
ggplot(graph_data1, aes(x = year, y = value)) +
  geom_line() + 
  geom_vline(xintercept = seq(2001, 2005, by = 0.001), 
             colour = "grey", linetype = "solid", 
             alpha = 0.01) +
  geom_blank(data = var_limits1) +
  facet_wrap(~type, ncol = 2, scales = "free") +
  labs(x = "Year", 
       y = "Lower Score = More Abuse; Higher Score = More Respect") +
  theme_bw() + 
  theme(legend.position = "bottom", legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14), 
        text = element_text(size = 13, family = "Times"),
        axis.title = element_text(size = 10), axis.text = element_text(size = 10))

# Saving the plot output for the presentation
ggsave(paste0("figures/fig1.png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")
```

# Figure 2
```{r fig2, cache=TRUE}
# Computing global-year averages for democracies and non-democracies for all var_names
trends_2 <- data_final %>% 
  group_by(year, active_d) %>% 
  summarise("Physical Integrity Score (CIRI)"      = mean(physint, na.rm = TRUE),
            "Latent Variable Model Score (Fariss)" = mean(latentmean, na.rm = TRUE),
            "Political Imprisonment Score (CIRI)"  = mean(polpris, na.rm = TRUE),
            "Disappearance Score (CIRI)"           = mean(disap, na.rm = TRUE))

# Formats the data to be graphed and makes the data facet on var_name
graph_data2 <- gather(trends_2, type, value, var_names)
graph_data2$type <- factor(graph_data2$type, levels = var_names) 

# Relabel active_d for legend using a loop
for (i in 1:length(graph_data2$active_d)){
  if (graph_data2$active_d[i] == 0){
    graph_data2$active_d[i] <- "Other States"
  }
  else if (graph_data2$active_d[i] == 1){
    graph_data2$active_d[i] <- "Active Participants"
  }
}

# Construct matrices to call min and max values for y-axis on facet plots
var_limits2 <- as_tibble(cbind(year = c(rep(1992:2011, times = 4, each = 2)),
                               active_d = c(rep(0:1, times = 40)),
                               value = c(rep(c(0,8),    20), 
                                         rep(c(-0.5,1), 20), 
                                         rep(c(0,2),    20), 
                                         rep(c(0,2),    20))))

# Assign variable names
var_limits2$type <- rep(var_names[1:4], times = 1, each = 40)

# Converts labels to factors to order plot facets
var_limits2$type <- factor(var_limits2$type, levels = var_names)


# Create plots
## Figure 2
ggplot(graph_data2, aes(x = year, y = value, group = active_d)) +
  geom_line(aes(linetype = factor(active_d))) + 
  geom_vline(xintercept = seq(2001, 2005, by = 0.001), 
             colour="grey", linetype = "solid", 
             alpha = 0.01) +
  geom_blank(data = var_limits2) +
  facet_wrap(~type, ncol=2, scales = "free") +
  labs(x = "Year", 
       y = "Lower Score = More Abuse; Higher Score = More Respect") +
  theme_bw() + 
  theme(legend.position = "bottom", legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14), 
        text = element_text(size = 13, family = "Times"),
        axis.title = element_text(size = 10), axis.text = element_text(size = 10))

# Saving the plot output for the presentation
ggsave(paste0("figures/fig2.png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")
```

# Figure 3
```{r fig3, cache=TRUE}
# Computing global-year averages for democracies and non-democracies for all var_names
trends_3 <- data_final %>% 
  group_by(year, active_d) %>% 
  filter(below_polity == 1) %>%
  summarise("Physical Integrity Score (CIRI)"      = mean(physint, na.rm = TRUE),
            "Latent Variable Model Score (Fariss)" = mean(latentmean, na.rm = TRUE),
            "Political Imprisonment Score (CIRI)"  = mean(polpris, na.rm = TRUE),
            "Disappearance Score (CIRI)"           = mean(disap, na.rm = TRUE))

# Formats the data to be graphed and makes the data facet on var_name
graph_data3 <- gather(trends_3, type, value, var_names)
graph_data3$type <- factor(graph_data3$type, levels = var_names) 

# Relabel active_d for legend using a loop
for (i in 1:length(graph_data3$active_d)){
  if (graph_data3$active_d[i] == 0){
    graph_data3$active_d[i] <- "Other States"
  }
  else if (graph_data3$active_d[i] == 1){
    graph_data3$active_d[i] <- "Active Participants"
  }
}

# Adjust y-axis for Fariss data
var_limits3 <- as_tibble(cbind(year = c(rep(1992:2011, times = 4, each = 2)),
                                   active_d = c(rep(0:1, times = 40)),
                                   value = c(rep(c(0,8),    20), 
                                             rep(c(-1,0.5), 20), 
                                             rep(c(0,2),    20), 
                                             rep(c(0,2),    20))))

# Assign variable names
var_limits3$type <- rep(var_names[1:4], times = 1, each = 40)

# Converts labels to factors to order plot facets
var_limits3$type <- factor(var_limits3$type, levels = var_names)

# Create Plots
# Figure 3
ggplot(graph_data3, aes(x = year, y = value, group = active_d)) +
  geom_line(aes(linetype = factor(active_d))) + 
  geom_vline(xintercept = seq(2001, 2005, by = 0.001), 
             colour="grey", linetype = "solid", 
             alpha = 0.01) +
  geom_blank(data = var_limits3) +
  facet_wrap(~type, ncol=2, scales = "free") +
  labs(x = "Year", 
       y = "Lower Score = More Abuse; Higher Score = More Respect") +
  theme_bw() + 
  theme(legend.position = "bottom", legend.title = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14), 
        text = element_text(size = 13, family = "Times"),
        axis.title = element_text(size = 10), axis.text = element_text(size = 10))

# Saving the plot output for the presentation
ggsave(paste0("figures/fig3.png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")
```

\newpage
# Tables
```{r setting_models, results='asis', cache=TRUE}
# This block is devoted to the definition of the different models that are 
# used in the creation of the table for the analysis. The blocks with the tables
# follow after. The general structure of the construction of the models is 
# (1) to intialize and empty data set to be appended to later, (2) setting
# up the formula to be used in the linear model, (3) calculating the model,
# (4) extracting the coefficients for each imputation, (5) aggregating these,
# (6) inputting these numbers into a plm object whcih will be the direct output 
# of the table.

# Creates a function to compute the variance across the imputations. The value
# outputted from this function will be used in the table and will be the
# standard error shown. [se = standard error, betas = estimate coefficients] The
# 2 in the apply function is the margin which means that the function will be
# applied to the columns of whatever the model inputted is.
aggregate_se <- function(betas, se){
  # Calculating the variance for the standard errors
  t_one <- apply(se, 2, 
                 function(x) sum(x^2)/length(x) )
  
  # Calculating the variance for the estimate coefficients
  t_two <- apply(betas, 2, 
                 function(x) sum((x - mean(x))^2 / (length(x) - 1)) * (1 + (1 / length(x))) )
  
  # Adding the variances and returning the total variance
  t_one + t_two
}

# General Function for Model 1
mod_1 <- function(DV, LAG_DV){
  ## Creating an empty matrix to be used to store the future values for the
  ## estimated coefficients (betas), and the standard errors (std.error).
  betas <- matrix(NA, nrow = imps, ncol = 2) # Matrix for estimated coefficients 
  st.errors <- matrix(NA, nrow = imps, ncol = 2) # Matrix for standard errors 
  
  ## This will be a formula used to build the model
  fmla <- formula(paste0(substitute(DV), "~ active_t +", substitute(LAG_DV)))
  
  # Create a linear model and save standard errors for each imputed dataset
  for (i in 1:imps){
    ## plm is a linear model for panel data: will allow us to save standard errors
    ## for the imputed dataset
    mod <- plm(fmla, 
               data=data$imputations[[i]], 
               index=c("COW", "YEAR"), 
               effect ="twoways", model="within") 
    
    # Computing the country level cluster robust standard errors
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group")) 
    
    # Saving the relevant values for each of the imputations: estimate
    # coefficients and standard errors. These will be later aggregated to
    # calculate the values used in the table
    ## Estimate Coefficients
    betas[i,] <- mod[,1]
    ## Standard Errors
    st.errors[i,] <- mod[,2] 
  }
  
  # Aggregated the estimate coefficient and standard error for all of the
  # imputations. This will be the value in the table.
  ## Mean estimate coefficient
  beta_estimates <- colMeans(betas)  
  ## Aggregated standard error: uses the function created above
  crse_estimates <- aggregate_se(betas, st.errors) 
  
  # Inserting the correct coefficient and standard error values into the plm
  # object to be inputted into the table
  ## Creates a placeholder plm object using the first imputation
  mod <- plm(fmla, data = data$imputations[[1]], 
             index=c("COW", "YEAR"), effect ="twoways", model="within")
  
  ## Replacing the values of the plm object
  for(i in 1:length(colMeans(betas))){
    mod$coefficients[[i]] <- beta_estimates[i]
  }
  
  ## Replacing the variances using the diagonal of the plm variance-covariance matrix
  diag(mod$vcov) <- crse_estimates
  
  ## Outputting the model
  mod
}

# General Function for Model 2
mod_2 <- function(DV, LAG_DV){
  ## Creating an empty matrix to be used to store the future values for the
  ## estimated coefficients (betas), and the standard errors (std.error).
  betas <- matrix(NA, nrow = imps, ncol = 3)
  st.errors <- matrix(NA, nrow = imps, ncol = 3)
  
  ## This will be a formula used to build the model
  fmla <- formula(paste0(substitute(DV)," ~ Dem_Part + Auto_Part +", substitute(LAG_DV)))
  
  # Create a linear model and save standard errors for each imputed dataset
  for (i in 1:imps){
    ## plm is a linear model for panel data: will allow us to save standard errors
    ## for the imputed dataset
    mod <- plm(fmla, 
               data = data$imputations[[i]], 
               index=c("COW", "YEAR"), 
               effect ="twoways", model="within")
    
    # Computing the country level cluster robust standard errors
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group"))
    
    # Saving the relevant values for each of the imputations: estimate
    # coefficients and standard errors. These will be later aggregated to
    # calculate the values used in the table
    ## Estimate Coefficients
    betas[i,] <- mod[,1]
    ## Standard Errors
    st.errors[i,] <- mod[,2]
  }

  # Aggregated the estimate coefficient and standard error for all of the
  # imputations. This will be the value in the table.
  ## Mean estimate coefficient
  beta_estimates <- colMeans(betas)  
  ## Aggregated standard error: uses the function created above
  crse_estimates <- aggregate_se(betas, st.errors) 
  
  # Inserting the correct coefficient and standard error values into the plm
  # object to be inputted into the table
  ## Creates a placeholder plm object using the first imputation
  mod <- plm(fmla, data = data$imputations[[1]], 
             index=c("COW", "YEAR"), effect ="twoways", model="within")
  
  ## Replacing the values of the plm object
  for(i in 1:length(colMeans(betas))){
    mod$coefficients[[i]] <- beta_estimates[i]
  }
  
  ## Replacing the variances using the diagonal of the plm variance-covariance matrix
  diag(mod$vcov) <- crse_estimates
  
  ## Outputting the model
  mod 
}

# General Function for Model 3
mod_3 <- function(DV, LAG_DV){
  ## Creating an empty matrix to be used to store the future values for the
  ## estimated coefficients (betas), and the standard errors (std.error).
  betas <- matrix(NA, nrow = imps, ncol = 10)
  st.errors <- matrix(NA, nrow = imps, ncol = 10)
  
  ## This will be a formula used to build the model
  fmla <- formula(paste0(substitute(DV), "~ active_t + ucdp_type3 + gtd + trans + 
                         polity2 + log_pop + log_gdppc + log_UStrade + log_USmilaid +", 
                         substitute(LAG_DV)))
  
  # Create a linear model and save standard errors for each imputed dataset
  for (i in 1:imps){
    ## plm is a linear model for panel data: will allow us to save standard errors
    ## for the imputed dataset
    mod <- plm(fmla, 
               data = data$imputations[[i]], 
               index=c("COW", "YEAR"), 
               effect ="twoways", model="within")
    
    # Computing the country level cluster robust standard errors
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group"))
    
    # Saving the relevant values for each of the imputations: estimate
    # coefficients and standard errors. These will be later aggregated to
    # calculate the values used in the table
    ## Estimate Coefficients
    betas[i,] <- mod[,1]
    ## Standard Errors
    st.errors[i,] <- mod[,2]
  }
  
  # Aggregated the estimate coefficient and standard error for all of the
  # imputations. This will be the value in the table.
  ## Mean estimate coefficient
  beta_estimates <- colMeans(betas)  
  ## Aggregated standard error: uses the function created above
  crse_estimates <- aggregate_se(betas, st.errors) 
  
  # Inserting the correct coefficient and standard error values into the plm
  # object to be inputted into the table
  ## Creates a placeholder plm object using the first imputation
  mod <- plm(fmla, data = data$imputations[[1]], 
             index=c("COW", "YEAR"), effect ="twoways", model="within")
  
  ## Replacing the values of the plm object
  for(i in 1:length(colMeans(betas))){
    mod$coefficients[[i]] <- beta_estimates[i]
  }
  
  ## Replacing the variances using the diagonal of the plm variance-covariance matrix
  diag(mod$vcov) <- crse_estimates
  
  ## Outputting the model
  mod
}

# General Function for Model 4
mod_4 <- function(DV, LAG_DV){
  ## Creating an empty matrix to be used to store the future values for the
  ## estimated coefficients (betas), and the standard errors (std.error).
  betas <- matrix(NA, nrow = imps, ncol = 11)
  st.errors <- matrix(NA, nrow = imps, ncol = 11)
  
  ## This will be a formula used to build the model
  fmla <- formula(paste0(substitute(DV), "~ Dem_Part + Auto_Part + ucdp_type3 + gtd + 
                         trans + polity2 + log_pop + log_gdppc + log_UStrade + log_USmilaid +", 
                         substitute(LAG_DV)))
  
  # Create a linear model and save standard errors for each imputed dataset
  for (i in 1:imps){
    ## plm is a linear model for panel data: will allow us to save standard errors
    ## for the imputed dataset
    mod <- plm(fmla, 
               data = data$imputations[[i]], 
               index=c("COW", "YEAR"), 
               effect ="twoways", model="within")
    
    # Computing the country level cluster robust standard errors
    mod <- coeftest(mod, vcovHC(mod, type = "HC3", cluster = "group"))
    
    # Saving the relevant values for each of the imputations: estimate
    # coefficients and standard errors. These will be later aggregated to
    # calculate the values used in the table
    ## Estimate Coefficients
    betas[i,] <- mod[,1]
    ## Standard Errors
    st.errors[i,] <- mod[,2]
  }
  
  # Aggregated the estimate coefficient and standard error for all of the
  # imputations. This will be the value in the table.
  ## Mean estimate coefficient
  beta_estimates <- colMeans(betas)  
  ## Aggregated standard error: uses the function created above
  crse_estimates <- aggregate_se(betas, st.errors) 
  
  # Inserting the correct coefficient and standard error values into the plm
  # object to be inputted into the table
  ## Creates a placeholder plm object using the first imputation
  mod <- plm(fmla, data = data$imputations[[1]], 
             index=c("COW", "YEAR"), effect ="twoways", model="within")
  
  ## Replacing the values of the plm object
  for(i in 1:length(colMeans(betas))){
    mod$coefficients[[i]] <- beta_estimates[i]
  }
  
  ## Replacing the variances using the diagonal of the plm variance-covariance matrix
  diag(mod$vcov) <- crse_estimates
  
  ## Outputting the model
  mod
}
```

```{r table_setup}
# Defining the characteristics for the stargazer object
# Setting the covariate labels (those on the left-hand side)
covariate_names <- c("Participation", "Democratic participation", "Autocratic participation", 
                     "Internal conflicts", "Terrorist attacks", "Transitional state", 
                     "Polity score", "Log population", "Log GDP per capita", "Log US trade", 
                     "Log US military assistance")

# Setting up the line to show fixed effects
fe_line <- list(c("Fixed effects", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes"))

# Adding a footnote
footnote <- c("All models include country and year fixed effects and a 
              dependent variable lagged one year. Country level",
              "cluster-robust standard errors in parentheses. 
              $^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01")

# Setting the title
title1 <- "Participation in RDI program and state respect for human rights, 1992-2011"
```


```{r table2, results='asis', cache=TRUE}
# Run analysis and produce tables
## Table 1 for our analysis (table 2 in the paper)
stargazer(mod_1(PHYSINT, lag_physint), mod_2(PHYSINT, lag_physint),
          mod_3(PHYSINT, lag_physint), mod_4(PHYSINT, lag_physint),
          mod_1(latentmean, lag_latentmean), mod_2(latentmean, lag_latentmean),
          mod_3(latentmean, lag_latentmean), mod_4(latentmean, lag_latentmean),
          header = FALSE, style = "apsr", title = title1, digits = 3, 
          covariate.labels = covariate_names, add.lines = fe_line, 
          notes = footnote, notes.append = FALSE, notes.align = "l",
          font.size = "small", column.sep.width = "-8pt",
          omit = c("lag_physint", "lag_latentmean"),
          omit.stat = c("adj.rsq", "f"),
          dep.var.labels = c("Physical Integrity Score (CIRI)", 
                             "Latent Variable Model Score (Fariss)"))
```

```{r table3, results='asis', cache=TRUE}
# Run analysis and produce tables
## Table 2 for our analysis (table 3 in the paper)
stargazer(mod_1(DISAP, lag_disap), mod_2(DISAP, lag_disap),
          mod_3(DISAP, lag_disap), mod_4(DISAP, lag_disap),
          mod_1(POLPRIS, lag_polpris), mod_2(POLPRIS, lag_polpris),
          mod_3(POLPRIS, lag_polpris), mod_4(POLPRIS, lag_polpris),
          header = FALSE, style = "apsr", title = title1, digits = 3, 
          covariate.labels = covariate_names, add.lines = fe_line, 
          notes = footnote, notes.append = FALSE, notes.align = "l",
          font.size = "small", column.sep.width = "-8pt",
          omit = c("lag_disap", "lag_polpris"),
          omit.stat = c("adj.rsq", "f"),
          dep.var.labels = c("Disappearance Score (CIRI)", 
                             "Political Imprisonment Score (CIRI)"))
```

\newpage
# Extension
The extension is looking at the way that a country's human rights rating would change with the adoption of, participation in, or support of the CIA's RDI program. Using an indicator in the dataset, I was able to construct a profile for each of the different years to compare countries participating in and not participating in the program. An interesting thing to note in the dataset is that once a country was participating in the program, the data indicated that none of the countries backed out. The original paper (@cia_paper), included a note saying that this data was not readily available in their original dataset. If this data were available, it would be interested to have a better view of what was going on.


```{r extension_graph, cache=TRUE}
## In the data pre-processing done, the values for active participation are
## hard coded in. Not sure what the source of the data is, but assuming that it
## is reliable and without error. The data also includes active_t and active_d 
## which isn't very well documented, but I have reached the assumption that 
## active_t = active treatment and active_d = active data. I believe this is a 
## result of the imputation which was used to fill in data gaps.

## The active_t variable serves as the indicator for when the country first began 
## participating in the RDI program... Below I am looking to see (1) the country by
## country impact of the humanr rights score that participation had and (2) the time
## effect after joining....
# data_final %>%  
#   filter(active_t == 1) %>% 
#   glimpse() %>% 
#   ggplot(aes(x = year, y = physint)) +
#     geom_point() + 
#     facet_wrap(~country) 

## Creating a plot with number of new active participants in the RDI program by year
data_final %>% 
  filter(active_t == 1) %>% 
  distinct(cow, .keep_all = TRUE) %>% 
  arrange(year) %>% 
  count(year) %>% 
  ggplot(aes(x = year, y = n)) +
    geom_col(fill = "red") + 
    labs(title = "Number of Countries Actively Adopting the RDI Program",
         x = "Year",
         y = "# of Countries") +
    theme(text = element_text(family = "Times"))

# Saving the plot above
ggsave(paste0("figures/ext_countries.png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")

## Creating a master list for the countries that are active participants. I will
## be using this to construct a plot and table between actively participating
## countries and non-active countries.
### Master list with all years, RDI participants
rdi_countries <- data_final %>% 
  filter(active_t == 1) %>% 
  distinct(cow, .keep_all = TRUE) %>% 
  select(cow, country)


# Joined list with countries by year to see what changes, if any, exist
## This only contains countries active in the RDI program data across all years
## recorded.
joined_rdi <-  semi_join(data_final, rdi_countries, by = "cow") %>% 
  mutate(rdi = 1) %>% 
  group_by(year, rdi) %>% 
  mutate("Physical Integrity" = mean(physint, na.rm = TRUE)) %>% 
  gather(type, value, 
         c("Physical Integrity"))

## Contains countries without participation in the RDI program across all years
## using the anti-join to create the list.
joined_nrdi <- anti_join(data_final, joined_rdi, by = "cow") %>% 
  mutate(rdi = 0) %>% 
  group_by(year, rdi) %>% 
  mutate("Physical Integrity" = mean(physint, na.rm = TRUE)) %>% 
  gather(type, value, 
         c("Physical Integrity"))

## master list with all, now with an indicator of whether they are rdi countries 
## or not and the phyint calculated
joined_master <- full_join(joined_rdi, joined_nrdi) %>% 
  group_by(year, rdi) %>% 
  mutate("Physical Integrity" = mean(physint, na.rm = TRUE)) %>% 
  gather(type, value, 
         c("Physical Integrity"))

# Plotting the physical integrity scores across the non-RDI countries.
yr_notplot <- joined_master %>% 
  filter(rdi == 0) %>% 
  ggplot(aes(x = year, y = value)) +
    geom_point(color = "blue") + 
    geom_line(color = "blue") +
    labs(title = "Physical Integrity Score by Year for non-RDI Countries",
         x = "Year",
         y = "Score") +
    ylim(3.5, 6) +
    theme(text = element_text(family = "Times"))

# Saving the plot for non-RDI countries for use in the final paper
ggsave("figures/ext_nonrdi.png", 
       width = 9, height = 4.5, 
       plot = yr_notplot, 
       device = "png", dpi = "retina")


# Breaking it down into years for when countries joined the RDI program...
# This function will plot the human rights index for countries based on the year
# that they became active participants in the RDI program
rdi_year <- function(yr){
  # Filtering by those countries whoe joined the RDI program in the program's 
  # specified year. This then keeps the specified country and joins with the 
  # original dataset in order to get all of the country data, not just that 
  # for the years they were active in the RDI program. I then take the average
  # of the physical integrity across the countries that joined the RDI program
  # in the year indicated.
  rdi_joined <- data_final %>% 
    filter(active_t == 1, year == yr) %>% 
    distinct(cow, .keep_all = TRUE) %>% 
    select(cow, country) %>% 
    semi_join(data_final, ., by = "cow") %>% 
    group_by(year) %>%
    summarise("Physical Integrity" = mean(physint, na.rm = TRUE)) %>% 
    gather(type, value, 
           c("Physical Integrity"))  

  # Plotting the physical integrity scores across the countries.
  yr_plot <- rdi_joined %>% 
    ggplot(aes(x = year, y = value)) +
      geom_point(color = "orange") + 
      geom_line(color = "orange") +
      geom_vline(xintercept = eval(as.integer(yr))) +
      geom_point(data = joined_nrdi, aes(x = year, y = value), 
                 color = "blue") +
      geom_line(data = joined_nrdi, aes(x = year, y = value), 
                color = "blue") +
    ylim(3.5, 6) + 
      labs(title = paste0("Physical Integrity Score by Year for RDI Activated in ",substitute(yr)),
           subtitle = "RDI: orange, non-RDI: blue",
           x = "Year",
           y = "Score") +
      theme(text = element_text(family = "Times")) 
  
  ggsave(paste0("figures/ext_", substitute(yr), ".png"), 
       width = 9, height = 4.5, 
       plot = yr_plot, 
       device = "png", dpi = "retina")
  
  yr_plot
}

## Plotting and saving the plots for use in the final paper from the years that
## there were countries joining the RDI program
rdi_year("2001")
rdi_year("2002")
rdi_year("2003")
rdi_year("2004")
rdi_year("2005")

# Plotting across all years of joining v. not joining
ggplot(joined_rdi) +
  geom_point(aes(x = year, y = value),
             color = "orange") +
  geom_line(aes(x = year, y = value),
             color = "orange") +
  geom_point(data = joined_nrdi, aes(x = year, y = value), 
             colour = "blue") +
  geom_line(data = joined_nrdi, aes(x = year, y = value), 
             colour = "blue") +
  ylim(3.5,6) +
  labs(title = "Physical Integrity Score by Year for RDI v. non-RDI",
       subtitle = "RDI: orange, non-RDI: blue",
       x = "Year",
       y = "Score") +
  theme(text = element_text(family = "Times")) 

ggsave(paste0("figures/ext_allcountries", ".png"), 
       width = 9, height = 4.5, 
       plot = last_plot(), 
       device = "png", dpi = "retina")
  
# Test to ensure that the distinct countries worked properly
# rdi_2001 <- data_final %>% 
#   filter(active_t == 1 & year == 2001) %>% 
#   distinct(cow, .keep_all = TRUE) %>% 
#   select(cow, country)
```

```{r extension_table, results='asis'}
# Joined list with countries that are participating in the rdi program 
# by year to see what changes, if any, exist betwee
joined_rdi <- semi_join(data_final, rdi_countries, by = "cow")

mod_rdi <- glm(data = joined_rdi, 
               physint ~ dem_part + auto_part + ucdp_type3 + gtd + trans + polity2 + 
                 log_pop + log_gdppc + log_u_strade + log_u_smilaid)

mod_nrdi <- glm(data = joined_nrdi, 
                physint ~ dem_part + auto_part + ucdp_type3 + gtd + trans + polity2 + 
                  log_pop + log_gdppc + log_u_strade + log_u_smilaid)

cat("\\setcounter{table}{0}")
stargazer(mod_rdi, mod_nrdi,
          header = FALSE, style = "apsr", title = title1, digits = 3, 
          covariate.labels = covariate_names, add.lines = fe_line, 
          notes = footnote, notes.append = FALSE, notes.align = "l",
          font.size = "small", column.sep.width = "-8pt",
          omit.stat = c("adj.rsq", "f"),
          dep.var.labels = "Physical Integrity Score (CIRI)") 

# Saving the data to use stargazer in the final paper.
write_rds(joined_rdi, "figures/rdi_data.rds")
write_rds(joined_nrdi, "figures/nrdi_data.rds")
```

# References